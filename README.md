# **QSPLIT: Quantum Split Learning Testing Toolkit**



## **Tool Components**
![](https://cdn.discordapp.com/attachments/1149758290566324276/1414482634821599313/Fig3_8.png?ex=68bfbb1b&is=68be699b&hm=2c6dc7ef4dff312d8dcb6bc1fae3581a069c0337c882483f94cd3059c2899711&)

### **A. Part Selection**
The *Part Selection* section allows users to choose which components of a QNN architecture (**SE, PQC, MEA**) will be provided as **Target Code** and which will be automatically generated as **Dummy Code**.  
- **Target Code**: User-provided code uploaded through the section  
- **Dummy Code**: Remaining components are automatically generated by QSPLIT  


### **B-1. Target Code Layer**
The *Target Code Layer* section allows users to specify the detailed structure of the selected target code.


### **B-2. Target Code Hyperparameter**
The *Target Code Hyperparameter* section allows users to configure hyperparameters required for quantum split learning. It consists of two parts:  
- **Quantum Device**: Parameters for dummy code generation, such as number of qubits, batch size, and execution device  
- **Training**: Parameters for the training process, such as number of epochs, optimizer, and learning rate  



### **C. Dummy Code Generation**
The *Dummy Code Generation* section generates dummy codes based on the uploaded target code and configured parameters.  
- The number of generated dummy codes is determined by the `Number of Dummy Codes` hyperparameter  
- **Dummy List**: Displays the generated dummy codes on the GUI  
- Users can select each dummy code to inspect its internal structure (e.g., PQC layers and MEA measurements)  



### **D. Split Learning Execution**
By clicking the **Run** button in the *Dummy Code Generation* section, users can initiate split learning across multiple target-dummy combinations.  
- The training process is executed using the **TorchQuantum framework**  
- **Real-time training logs** (e.g., loss, accuracy) are displayed in the GUI, allowing users to monitor progress  



### **E. Result Visualization & Export**
The *Results* section displays the classification accuracy for each combination after split learning is completed.  
- Users can select a desired dummy code and click the **Export** button to save it as an executable `.py` file  
- Exported code is compatible with the **TorchQuantum** framework  
- This allows validated QNN components to be reused for **subsequent development**  

---

## **Key Features**
- **Automated Dummy Code Generation**  
- **Split Learning Execution**  
- **Real-time Log & Result Presentation**  
- **Code Export for Reusability**  

---

# HOW TO USE

## 1. How to Start

### 1) System Prerequisites
- **Python** ≥ 3.12  
- **Uvicorn**  
- **PyTorch** (tested with 2.8.0)  
- **TorchQuantum** (tested with 0.1.8)  
- **Flutter** 3.32.8 (for frontend)  
- A modern web browser (Chrome/Edge/Firefox)  

### 2) Setup
```bash
# create & activate venv (example)
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
```
```bash
# run backend
cd Backend
uvicorn app.main:app --host 0.0.0.0 --port 8000
```
```bash
# run frontend
cd Frontend/lib
flutter run -d ${web device} # chrome, edge, etc
```

---

## 2. Configure Components

- **Upload Target Code**: In *Part Selection*, click **Upload** button to provide any subset of SE / PQC / MEA as target code.  
- **Assign Roles**: Select each component as **Target Code** or **Dummy Code** (radio buttons; mutually exclusive).  
- **Parameter Input**: In *Target Code Hyperparameter*  
  - *Quantum Device*: number of qubits, batch size, execution device  
  - *Training*: epochs, optimizer, learning rate  
  - *Dataset*: Choose from datasets uploaded to QSPLIT (e.g., MedNIST)  

---

## 3. Generate Dummy Code

1. Configure parameters in *Target Code Hyperparameter*  
2. Click **Generate** button to create dummy code  
3. Inspect in *Dummy Code Generation → Dummy List*  
   - Example: PQC = RY/RZ/CNOT gate stack, MEA = Z observable  

---

## 4. Execute Split Learning

- In *Dummy Code Generation*, click **Run** button to start split learning across all combinations  
- Training uses *TorchQuantum*; per-epoch loss/accuracy are streamed in real time to the GUI  

---

## 5. Compare Results

- *Results* section lists accuracy and metrics per combination  
- Easily identify stable or high-performing combinations  

---

## 6. Export Code

- In *Results*, select a dummy code and click **Export** button  
- Outputs an executable `.py` file compatible with *TorchQuantum*  
- Enables reuse, extension, and integration into follow-up experiments or deployment  

---

## Software Version
### v1.0.0  
